{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud: Deep Neural Network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kev\\Anaconda3\\envs\\py35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing Fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data['normalizedAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data = data.drop(['Amount'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9        ...              V21       V22       V23  \\\n",
       "0  0.098698  0.363787        ...        -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425        ...        -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654        ...         0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024        ...        -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739        ...        -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normalizedAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0          0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0         -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0          1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0          0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0         -0.073403  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10        ...              V21       V22  \\\n",
       "0  0.098698  0.363787  0.090794        ...        -0.018307  0.277838   \n",
       "1  0.085102 -0.255425 -0.166974        ...        -0.225775 -0.638672   \n",
       "2  0.247676 -1.514654  0.207643        ...         0.247998  0.771679   \n",
       "3  0.377436 -1.387024 -0.054952        ...        -0.108300  0.005274   \n",
       "4 -0.270533  0.817739  0.753074        ...        -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \\\n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0   \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0   \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0   \n",
       "\n",
       "   normalizedAmount  \n",
       "0          0.244964  \n",
       "1         -0.342475  \n",
       "2          1.160686  \n",
       "3          0.140534  \n",
       "4         -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, data.columns != 'Class']\n",
    "y = data.iloc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10        ...              V20       V21  \\\n",
       "0  0.098698  0.363787  0.090794        ...         0.251412 -0.018307   \n",
       "1  0.085102 -0.255425 -0.166974        ...        -0.069083 -0.225775   \n",
       "2  0.247676 -1.514654  0.207643        ...         0.524980  0.247998   \n",
       "3  0.377436 -1.387024 -0.054952        ...        -0.208038 -0.108300   \n",
       "4 -0.270533  0.817739  0.753074        ...         0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   normalizedAmount  \n",
       "0          0.244964  \n",
       "1         -0.342475  \n",
       "2          1.160686  \n",
       "3          0.140534  \n",
       "4         -0.073403  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes: \n",
    "\n",
    "Supervised Learning -means we need to teach our network using input and expected output \n",
    "\n",
    "Input- is a new credit card transaction\n",
    "\n",
    "Output- if the transaction is fradulent or not\n",
    "\n",
    "The result is a Step Function so it only has a result of (0,1)\n",
    "\n",
    "The Sigmoid Activation Function is softer on the change from (0,1) since it gives a probability of being either (0,1)\n",
    "\n",
    "The Rectified Linear Unit (RELU) Activation Function is another option and this function returns a 0 for any negative value and a 1 for any positive value\n",
    "\n",
    "The Hyperbolic Tangent is\n",
    "\n",
    "\n",
    "Key Definitions within Back Propagation:\n",
    "\n",
    "Feed Forward- The process of calculating the output for a given input in a NN\n",
    "\n",
    "We will compare this with the expected output\n",
    "\n",
    "Epochs: The number of iterations ex. 500times\n",
    "\n",
    "Batch Size: The amount of records we will feed forward at once before starting the Back Propagation process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Notes:\n",
    "\n",
    "3 datasets: Training, Validation, Testing\n",
    "\n",
    "Training(10-40%) of Full Dataset: Used for Feed Forward and Back Propogate through the network\n",
    "\n",
    "Validation: Measure objectively the results of the training to re-evaluate the weights\n",
    "\n",
    "Testing: Used to evaluate the model based off those training sets\n",
    "\n",
    "All 3 should be representative of the full dataset however"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underfitting- if the model is too simple for the scenario you are trying to represent. If the issue is underfitting you can add more layers to the NN. \n",
    "\n",
    "Overfitting- if too complex for the scenario you are trying to represent. If this happens one method to use is called Dropout Layers which will randomly turn off layer weights to allow the NN to not overfit with the dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to create the 4 datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199364, 29)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443, 29)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_dim = 29,activation='relu'),\n",
    "    Dense(units=24,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(20,activation='relu'),\n",
    "    Dense(24,activation='relu'),\n",
    "    Dense(1,activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have Dropout Layers set to 0.5 so 50% chance of dropping random layered weights\n",
    "\n",
    "We are using RELU activation for everything except the last layer because we are doing a binary classification problem\n",
    "\n",
    "Units= Probability of fraud in each layer\n",
    "Input_Dim= how many columns to expect in the first layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                480       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                500       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                504       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 1,917\n",
      "Trainable params: 1,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "199364/199364 [==============================] - 11s 56us/step - loss: 0.0100 - acc: 0.9979\n",
      "Epoch 2/5\n",
      "199364/199364 [==============================] - 10s 52us/step - loss: 0.0041 - acc: 0.9993\n",
      "Epoch 3/5\n",
      "199364/199364 [==============================] - 11s 54us/step - loss: 0.0036 - acc: 0.9994\n",
      "Epoch 4/5\n",
      "199364/199364 [==============================] - 11s 54us/step - loss: 0.0035 - acc: 0.9994\n",
      "Epoch 5/5\n",
      "199364/199364 [==============================] - 11s 54us/step - loss: 0.0035 - acc: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x167c51e62b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size=15,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85443/85443 [==============================] - 1s 14us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004358851861420491, 0.9993445923013002]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85280    16]\n",
      " [   40   107]]\n"
     ]
    }
   ],
   "source": [
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[85280    16]\n",
      " [   40   107]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cnf_matrix, classes=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost every fradulant transaction was caught except for the 40 in (1,0). These were predicted as non-fradulent but were. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[284263     52]\n",
      " [   137    355]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "y_expected = pd.DataFrame(y)\n",
    "cnf_matrix = confusion_matrix(y_expected, y_pred.round())\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as the first Confusion Matrix but for different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
