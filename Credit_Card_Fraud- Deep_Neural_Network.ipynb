{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud: Deep Neural Network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kev\\Anaconda3\\envs\\py35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing Fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data['normalizedAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "data = data.drop(['Amount'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9        ...              V21       V22       V23  \\\n",
       "0  0.098698  0.363787        ...        -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425        ...        -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654        ...         0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024        ...        -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739        ...        -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normalizedAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0          0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0         -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0          1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0          0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0         -0.073403  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10        ...              V21       V22  \\\n",
       "0  0.098698  0.363787  0.090794        ...        -0.018307  0.277838   \n",
       "1  0.085102 -0.255425 -0.166974        ...        -0.225775 -0.638672   \n",
       "2  0.247676 -1.514654  0.207643        ...         0.247998  0.771679   \n",
       "3  0.377436 -1.387024 -0.054952        ...        -0.108300  0.005274   \n",
       "4 -0.270533  0.817739  0.753074        ...        -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \\\n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0   \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0   \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0   \n",
       "\n",
       "   normalizedAmount  \n",
       "0          0.244964  \n",
       "1         -0.342475  \n",
       "2          1.160686  \n",
       "3          0.140534  \n",
       "4         -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, data.columns != 'Class']\n",
    "y = data.iloc[:, data.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>normalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10        ...              V20       V21  \\\n",
       "0  0.098698  0.363787  0.090794        ...         0.251412 -0.018307   \n",
       "1  0.085102 -0.255425 -0.166974        ...        -0.069083 -0.225775   \n",
       "2  0.247676 -1.514654  0.207643        ...         0.524980  0.247998   \n",
       "3  0.377436 -1.387024 -0.054952        ...        -0.208038 -0.108300   \n",
       "4 -0.270533  0.817739  0.753074        ...         0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   normalizedAmount  \n",
       "0          0.244964  \n",
       "1         -0.342475  \n",
       "2          1.160686  \n",
       "3          0.140534  \n",
       "4         -0.073403  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes: \n",
    "\n",
    "Supervised Learning -means we need to teach our network using input and expected output \n",
    "\n",
    "Input- is a new credit card transaction\n",
    "\n",
    "Output- if the transaction is fradulent or not\n",
    "\n",
    "The result is a Step Function so it only has a result of (0,1)\n",
    "\n",
    "The Sigmoid Activation Function is softer on the change from (0,1) since it gives a probability of being either (0,1)\n",
    "\n",
    "The Rectified Linear Unit (RELU) Activation Function is another option and this function returns a 0 for any negative value and a 1 for any positive value\n",
    "\n",
    "The Hyperbolic Tangent is\n",
    "\n",
    "\n",
    "Key Definitions within Back Propagation:\n",
    "\n",
    "Feed Forward- The process of calculating the output for a given input in a NN\n",
    "\n",
    "We will compare this with the expected output\n",
    "\n",
    "Epochs: The number of iterations ex. 500times\n",
    "\n",
    "Batch Size: The amount of records we will feed forward at once before starting the Back Propagation process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Notes:\n",
    "\n",
    "3 datasets: Training, Validation, Testing\n",
    "\n",
    "Training(10-40%) of Full Dataset: Used for Feed Forward and Back Propogate through the network\n",
    "\n",
    "Validation: Measure objectively the results of the training to re-evaluate the weights\n",
    "\n",
    "Testing: Used to evaluate the model based off those training sets\n",
    "\n",
    "All 3 should be representative of the full dataset however"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underfitting- if the model is too simple for the scenario you are trying to represent. If the issue is underfitting you can add more layers to the NN. \n",
    "\n",
    "Overfitting- if too complex for the scenario you are trying to represent. If this happens one method to use is called Dropout Layers which will randomly turn off layer weights to allow the NN to not overfit with the dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to create the 4 datasets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199364, 29)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85443, 29)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_dim = 29,activation='relu'),\n",
    "    Dense(units=24,activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(20,activation='relu'),\n",
    "    Dense(24,activation='relu'),\n",
    "    Dense(1,activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have Dropout Layers set to 0.5 so 50% chance of dropping random layered weights\n",
    "\n",
    "We are using RELU activation for everything except the last layer because we are doing a binary classification problem\n",
    "\n",
    "Units= Probability of fraud in each layer\n",
    "Input_Dim= how many columns to expect in the first layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                480       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                500       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 24)                504       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 1,917\n",
      "Trainable params: 1,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "199364/199364 [==============================] - 11s 56us/step - loss: 0.0100 - acc: 0.9979\n",
      "Epoch 2/5\n",
      "199364/199364 [==============================] - 10s 52us/step - loss: 0.0041 - acc: 0.9993\n",
      "Epoch 3/5\n",
      "199364/199364 [==============================] - 11s 54us/step - loss: 0.0036 - acc: 0.9994\n",
      "Epoch 4/5\n",
      "199364/199364 [==============================] - 11s 54us/step - loss: 0.0035 - acc: 0.9994\n",
      "Epoch 5/5\n",
      "199364/199364 [==============================] - 11s 54us/step - loss: 0.0035 - acc: 0.9994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x167c51e62b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size=15,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85443/85443 [==============================] - 1s 14us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004358851861420491, 0.9993445923013002]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85280    16]\n",
      " [   40   107]]\n"
     ]
    }
   ],
   "source": [
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[85280    16]\n",
      " [   40   107]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cnf_matrix, classes=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost every fradulant transactions were caught except for the 36 in (1,0) who were predicted as non-fradulent but were. (36/150) were not caught."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
